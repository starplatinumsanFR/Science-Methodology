{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8125b179-2f9f-467a-a46f-df21ae8266cf",
   "metadata": {},
   "source": [
    "# Parallel Quicksort Performance Analysis\n",
    "## Science Methodology, Confidence Interval & Performance Evaluation (solo work)\n",
    "**Author:** Andrei Bituleanu\n",
    "\n",
    "This experiment aims to evaluate the performance of a parallel quicksort implementation in C using Pthreads, compared against its sequential variant.\n",
    "\n",
    "The primary objective is to understand:\n",
    "- How the number of threads or array size impacts sorting performance.\n",
    "- At what point parallelism provides a measurable speed-up.\n",
    "- How thread management overhead affects runtime efficiency.\n",
    "\n",
    "All tests were executed on a machine with an 8-core processor (2.90 GHz) using GCC (pthread) and analyzed in a Jupyter Notebook environment for visualization and computation reproducibility.\n",
    "\n",
    "All results and visualizations in this report are generated from code cells executed below.\n",
    "\n",
    "### All source code below comes from the parallelQuicksort.c file by Joshua Stough and Arnaud Legrand:\n",
    "\n",
    "**https://gricad-jupyter.univ-grenoble-alpes.fr/hub/user-redirect/lab/tree/Science-Methodology/exercice1/quicksort.ipynb**\n",
    "\n",
    "Below is a sanity test to make sure everything works as intended. As you can see, by default, the sequential is significatively more efficient than its parallel counterpart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f997c48d-6317-465a-afeb-ae252050eccb",
   "metadata": {},
   "source": [
    "%cd /home/bituleaa/notebooks/Science-Methodology/exercice1\n",
    "!./M2R-ParallelQuicksort/src/parallelQuicksort 1000000\n",
    "\n",
    "After verifying the program’s correctness with a baseline test (`N = 1,000,000`), I extended the analysis to study how parallel quicksort performance scales when varying the array size with larger numbers.\n",
    "\n",
    "Initially, I experimented with increasing array sizes defined by `N = 10,000,000 × i`, where `i` is the iteration number.  \n",
    "At this stage, the number of threads was constant (THREAD_LEVEL = 10).  \n",
    "The results revealed that the sequential quicksort consistently and often narrowly outperformed the parallel version at 10 threads.\n",
    "\n",
    "This indicates that the limitation does not lie in the idea of parallelism itself, but rather in its implementation strategy.\n",
    "\n",
    "To document the first scaling experiment, where I varied the array size while keeping the thread count constant to 10,  \n",
    "the following code snippet outlines the procedure used to collect runtimes and confidence intervals.\n",
    "\n",
    "First start by running the next cell once, if you encounter an error trying to run any other code that will come after, \n",
    "that will compile the file. Then you may run the code snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf208a2e-70fa-4e8b-9efd-83dd6efa302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -O2 -pthread -DTHREAD_LEVEL=10 M2R-ParallelQuicksort/src/parallelQuicksort.c -o M2R-ParallelQuicksort/src/parallelQuicksort\n",
    "!chmod +x M2R-ParallelQuicksort/src/parallelQuicksort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3dad554-c588-466c-81ff-9a54eaef06ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running test with N = 10,000,000 ===\n",
      "Run 1:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 1.575684 sec.\n",
      "Parallel quicksort took: 2.693161 sec.\n",
      "Built-in quicksort took: 4.141856 sec.\n",
      "Run 2:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 1.443216 sec.\n",
      "Parallel quicksort took: 2.951239 sec.\n",
      "Built-in quicksort took: 4.160295 sec.\n",
      "Run 3:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 1.495248 sec.\n",
      "Parallel quicksort took: 2.898793 sec.\n",
      "Built-in quicksort took: 4.175829 sec.\n",
      "Run 4:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 1.482642 sec.\n",
      "Parallel quicksort took: 2.941967 sec.\n",
      "Built-in quicksort took: 4.178306 sec.\n",
      "Run 5:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 1.464856 sec.\n",
      "Parallel quicksort took: 3.109609 sec.\n",
      "Built-in quicksort took: 4.169508 sec.\n",
      "\n",
      "=== Running test with N = 20,000,000 ===\n",
      "Run 1:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 3.072275 sec.\n",
      "Parallel quicksort took: 5.216670 sec.\n",
      "Built-in quicksort took: 8.679066 sec.\n",
      "Run 2:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 3.012083 sec.\n",
      "Parallel quicksort took: 5.002297 sec.\n",
      "Built-in quicksort took: 8.646280 sec.\n",
      "Run 3:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 3.079823 sec.\n",
      "Parallel quicksort took: 5.606016 sec.\n",
      "Built-in quicksort took: 8.709523 sec.\n",
      "Run 4:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 3.121110 sec.\n",
      "Parallel quicksort took: 5.739470 sec.\n",
      "Built-in quicksort took: 8.660732 sec.\n",
      "Run 5:\n",
      "Thread value = 10 \n",
      "Sequential quicksort took: 3.113612 sec.\n",
      "Parallel quicksort took: 5.031180 sec.\n",
      "Built-in quicksort took: 8.771837 sec.\n",
      "\n",
      " Raw results saved to parallel_quicksort_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# Run this code snippet to reproduce my analysis.\n",
    "\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "exe_path = \"./M2R-ParallelQuicksort/src/parallelQuicksort\"\n",
    "\n",
    "# 5 repetitions per test to ensure a confidence interval\n",
    "repetitions = 5\n",
    "results = []\n",
    "\n",
    "for i in range(1, 3):  # N = 10M, 20M, 30M\n",
    "    N = 10_000_000 * i\n",
    "    print(f\"\\n=== Running test with N = {N:,} ===\")\n",
    "    for r in range(repetitions):\n",
    "        result = subprocess.run([exe_path, str(N)], capture_output=True, text=True)\n",
    "        output = result.stdout.strip()\n",
    "        print(f\"Run {r+1}:\")\n",
    "        print(output)\n",
    "        results.append({\"N\": N, \"output\": output})\n",
    "\n",
    "df_raw = pd.DataFrame(results)\n",
    "df_raw.to_csv(\"parallel_quicksort_raw.csv\", index=False)\n",
    "print(\"Results saved to parallel_quicksort_raw.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fdac8e5-a22d-40bf-80a6-29dabcf16b2b",
   "metadata": {},
   "source": [
    "From the results, it becomes clear that regardless of the array size, the sequential version consistently achieves better runtimes than the parallel one.\n",
    "\n",
    "**You may want to view the CSV file that it generated.**\n",
    "    \n",
    "Since the increasing the array size doesn't make any notable change to the efficiency of both algorithm's ratio, we can exclude the risk of\n",
    "a Simpson paradox and move onto the next experiment where the thread count will change and the array size will remain constant, at an arbitrarily high array size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22900e6c-6107-4118-aea0-d8665682afdf",
   "metadata": {},
   "source": [
    "Experimental Direction 2 : Changing Thread levels at a constant N array size\n",
    "\n",
    "After confirming that increasing array size does not make the parallel quicksort outperfmorm the sequential one,\n",
    "the next step is to investigate how the number of threads (THREAD_LEVEL) influences performance for a fixed, large array size.\n",
    "\n",
    "In this experiment:\n",
    "\n",
    "The array size N is kept constant at 10 000 000 elements.\n",
    "\n",
    "The number of threads is varied across the values: 1, 2, 4, 6, 8, 10.\n",
    "\n",
    "All results are saved automatically to a CSV for reproducibility and reused as is in my D3.js visualization.\n",
    "\n",
    "The goal is to determine whether increasing thread depth ever leads to performance gains,\n",
    "or whether synchronization and thread management overhead remain dominant even at large workloads.\n",
    "\n",
    "Each configuration is executed 5 times to estimate a variability that computes a 95% confidence interval on the mean runtime.\n",
    "\n",
    "For each run we store sequential, parallel and built-in quicksort. For each group we compute the mean execution time, and a 95% confidence interval around the mean.\n",
    "\n",
    "You may now run the code snippet below to reproduce the results for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cdc255b-5d2a-4015-9a9f-f8daa5526013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread_Level</th>\n",
       "      <th>N</th>\n",
       "      <th>seq_mean</th>\n",
       "      <th>seq_ci_low</th>\n",
       "      <th>seq_ci_high</th>\n",
       "      <th>par_mean</th>\n",
       "      <th>par_ci_low</th>\n",
       "      <th>par_ci_high</th>\n",
       "      <th>builtin_mean</th>\n",
       "      <th>builtin_ci_low</th>\n",
       "      <th>builtin_ci_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1.493698</td>\n",
       "      <td>1.434769</td>\n",
       "      <td>1.552627</td>\n",
       "      <td>1.629095</td>\n",
       "      <td>1.494983</td>\n",
       "      <td>1.763207</td>\n",
       "      <td>4.165114</td>\n",
       "      <td>4.055896</td>\n",
       "      <td>4.274332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1.508157</td>\n",
       "      <td>1.419384</td>\n",
       "      <td>1.596931</td>\n",
       "      <td>1.824345</td>\n",
       "      <td>1.660412</td>\n",
       "      <td>1.988278</td>\n",
       "      <td>4.189956</td>\n",
       "      <td>4.083794</td>\n",
       "      <td>4.296118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1.500801</td>\n",
       "      <td>1.459204</td>\n",
       "      <td>1.542398</td>\n",
       "      <td>2.333883</td>\n",
       "      <td>1.686856</td>\n",
       "      <td>2.980910</td>\n",
       "      <td>4.179431</td>\n",
       "      <td>4.116147</td>\n",
       "      <td>4.242715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1.503671</td>\n",
       "      <td>1.470038</td>\n",
       "      <td>1.537304</td>\n",
       "      <td>2.760795</td>\n",
       "      <td>2.380700</td>\n",
       "      <td>3.140890</td>\n",
       "      <td>4.172008</td>\n",
       "      <td>4.117593</td>\n",
       "      <td>4.226423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1.480241</td>\n",
       "      <td>1.444348</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>2.663174</td>\n",
       "      <td>2.360561</td>\n",
       "      <td>2.965788</td>\n",
       "      <td>4.170254</td>\n",
       "      <td>4.050492</td>\n",
       "      <td>4.290015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1.463958</td>\n",
       "      <td>1.428650</td>\n",
       "      <td>1.499267</td>\n",
       "      <td>2.714815</td>\n",
       "      <td>2.433962</td>\n",
       "      <td>2.995668</td>\n",
       "      <td>4.177069</td>\n",
       "      <td>4.114171</td>\n",
       "      <td>4.239967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Thread_Level         N  seq_mean  seq_ci_low  seq_ci_high  par_mean  \\\n",
       "0             1  10000000  1.493698    1.434769     1.552627  1.629095   \n",
       "1             2  10000000  1.508157    1.419384     1.596931  1.824345   \n",
       "2             4  10000000  1.500801    1.459204     1.542398  2.333883   \n",
       "3             6  10000000  1.503671    1.470038     1.537304  2.760795   \n",
       "4             8  10000000  1.480241    1.444348     1.516133  2.663174   \n",
       "5            10  10000000  1.463958    1.428650     1.499267  2.714815   \n",
       "\n",
       "   par_ci_low  par_ci_high  builtin_mean  builtin_ci_low  builtin_ci_high  \n",
       "0    1.494983     1.763207      4.165114        4.055896         4.274332  \n",
       "1    1.660412     1.988278      4.189956        4.083794         4.296118  \n",
       "2    1.686856     2.980910      4.179431        4.116147         4.242715  \n",
       "3    2.380700     3.140890      4.172008        4.117593         4.226423  \n",
       "4    2.360561     2.965788      4.170254        4.050492         4.290015  \n",
       "5    2.433962     2.995668      4.177069        4.114171         4.239967  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this code if needed to test again the results of 5 repetitions alongside the calculation of the CI computation on your machine.\n",
    "# If desired, use your new CSV file generated and replace it in repo you will have cloned to your machine to run its D3.js visualization.\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "raw = pd.read_csv(\"parallel_quicksort_threads_raw.csv\")\n",
    "\n",
    "def extract_times(out: str):\n",
    "    seq = re.search(r\"Sequential quicksort took:\\s*([0-9.eE+-]+)\\s*sec\\.\", out)\n",
    "    par = re.search(r\"Parallel quicksort took:\\s*([0-9.eE+-]+)\\s*sec\\.\", out)\n",
    "    bi  = re.search(r\"Built-in quicksort took:\\s*([0-9.eE+-]+)\\s*sec\\.\", out)\n",
    "    return pd.Series({\n",
    "        \"time_seq\": float(seq.group(1)),\n",
    "        \"time_par\": float(par.group(1)),\n",
    "        \"time_builtin\": float(bi.group(1)),\n",
    "    })\n",
    "\n",
    "df = pd.concat(\n",
    "    [raw.drop(columns=[\"Output\"]), raw[\"Output\"].astype(str).apply(extract_times)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "def mean_ci95(x: pd.Series):\n",
    "    x = x.to_numpy()\n",
    "    n = len(x)\n",
    "    mean = x.mean()\n",
    "    std = x.std(ddof=1)\n",
    "    half = t.ppf(0.975, n - 1) * std / np.sqrt(n)\n",
    "    return pd.Series({\"mean\": mean, \"ci_low\": mean - half, \"ci_high\": mean + half})\n",
    "\n",
    "seq = df.groupby([\"Thread_Level\", \"N\"])[\"time_seq\"].apply(mean_ci95).unstack().add_prefix(\"seq_\")\n",
    "par = df.groupby([\"Thread_Level\", \"N\"])[\"time_par\"].apply(mean_ci95).unstack().add_prefix(\"par_\")\n",
    "bi  = df.groupby([\"Thread_Level\", \"N\"])[\"time_builtin\"].apply(mean_ci95).unstack().add_prefix(\"builtin_\")\n",
    "\n",
    "summary_min = seq.join(par).join(bi).reset_index()\n",
    "\n",
    "summary_min.to_csv(\"parallel_quicksort_threads_ci_min.csv\", index=False)\n",
    "\n",
    "summary_min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb1ded-94fa-4263-8d5a-d73675f2642b",
   "metadata": {},
   "source": [
    "I brought a small adjustment to the code by removing the #define THREAD_LEVEL 1 for the lines below so I wouldn't get an error when changing the Thread level for every new test run:\n",
    "\n",
    "`ifndef THREAD_LEVEL`\n",
    "`define THREAD_LEVEL 1`\n",
    "`endif`\n",
    "\n",
    "I invite you, if needed, to admire the table in the file generated from the code snippet, but for a more complete\n",
    "visualisation of our results, below is the d3.js graph of the code we just ran, reproduction of the test should globally\n",
    "be very similar as only the machine could make a slight influence in absolute results, but the graph should be virtually\n",
    "the same. The code is always accessible if need on this Github repo at :\n",
    "**Science-Methodology/exercice1/M2R-ParallelQuicksort/src/parallelQuicksort.c**\n",
    "\n",
    "Anyway, let's observe our results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849d2fb-3692-4576-ae48-4745d4794469",
   "metadata": {},
   "source": [
    "The link to the html page showing off the graph is the following since there's boxes to read when hovering over a point:\n",
    "\n",
    "https://starplatinumsanfr.github.io/Quicksort-Analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82665125-299b-41ca-8225-3f7480338f39",
   "metadata": {},
   "source": [
    "![threadlevel](threadlevel.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a373c-66fb-42a1-913a-54db824ed067",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "First of all, each point in the mean runtime has 5 repetitions. The cloudy area with the whiskers serve as the 95% confidence interval. The CI was computed offline, on a GA502I Asus\n",
    "laptop model without using the charging port. We used a discrete parameter for the Thread levels so any cloud or potential value observed outside of a specific x value is out of scope and irrelevant\n",
    "except if we wanna look at the variance visually.\n",
    "\n",
    "**Built-in algorithm** : We are gonna pass by this one fast, but it seems like the built-in algorithm remains pretty stable and consistent regardless of the thread count, standing as\n",
    "the slowest runtime by far.\n",
    "\n",
    "**Sequential algorithm** : This one seems to be clearly the best and most efficient algorithm regardless of the thread level for N = 10 000 000, the only time it COULD be advantageous\n",
    "to use parallelism is when we only use 1 thread, which could imply that a single thread level is easier to manage for paralellism when the count is only in the tens of millions. However,\n",
    "we can notice that the sequential algorithm seems to be the most unstable when the thread level = 2 as the variability of runtimes over 5 tests varies the most between the min and max,\n",
    "but no where near as much as the parallel algorithm.\n",
    "\n",
    "**Parallel algorithm** : This quicksort algorithm has a much wider CI, especially starting at 4 threads, but the variability is the most extreme at 4 threads too. This could be due \n",
    "to the way parallelism uses non-determinism, by using thread scheduling, synchronization and memory contention. The highest variability suggests a less predictable performance\n",
    "for N = 10 000 000. More threads would be required to draw such a conclusion, but the runtime seems to stabilise for the mean starting at 6 threads for parallelism.\n",
    "\n",
    "For all thread levels except for THREAD_LEVEL = 1, the parallel and sequential CI do not overlap, which suggests that indeed the performance gap is statistically significant and it's\n",
    "not due to noise. For such a count of items in an array, the thread management and synchronization costs are not worth it to replace sequentialism with paralellism. However, if \n",
    "stability is what we desire, the built-in algorithm is better suited, yet much slower than the other two up to 10 threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d34e4-b1c6-44eb-be71-1a54614edb4c",
   "metadata": {},
   "source": [
    "We are now gonna proceed to do a linear regression to quantify the relationship we just stated. We are gonna perform a linear regression on speedup as we are here only working with and analysing variance in thread levels.\n",
    "\n",
    "We are still talking about N = 10 000 000 and below as seen in the first code snippet.\n",
    "\n",
    "**The formula for speedup is pretty simple, it's basically the Speedup(p) = the mean runtime of the sequential algorithm over the mean runtime of the parallel algorithm for a given p thread level.**\n",
    "We know that if the Speedup(p) is greater than 1, then parallelism is more efficient, if it's = 1 then we get no gain and finally lesser than 1 means parallelism is slower than the sequential algorithm.\n",
    "\n",
    "With that formula, we will get a linear regression of Speedup(p) = α⋅p + β , where p is the thread level, α the speedup gained for each extra thread and β the intercept.\n",
    "α > 0 would mean the slope being positive and adding threads will increase speedup.\n",
    "a = 0 would mean we gain no speedup from an increased thread count.\n",
    "α < 0 would mean we actually lose speed by increasing thread count.\n",
    "\n",
    "In addition to the slope α and intercept β, we also report the coefficient of determination, R2 which measures how well the linear regression model explains the observed data.\n",
    "The closer R2 is to 1, the more the data follows a straight line, the closer it is to 0, the more the model shows no linear relationship.\n",
    "\n",
    "Here is what we got from applying those formulas with the data from the CSV table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347ac8a-681f-47dc-9ede-ff7e00b43cb8",
   "metadata": {},
   "source": [
    "![linear-regression](regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4112506-1084-46e8-81d6-0382c3bb8881",
   "metadata": {},
   "source": [
    "The speedup linear regression confirms our earlier observations made with the confidence intervals. First all our observed values remain strictly below 1 for all tested thread levels which suggests that in fact an array size of N = 10 000 000 is too small for the parallelism algorithm implementation to be more worth it than the sequential one, in fact, it is consistently slower and only gets slower with a higher thread count. Therefore, adding more threads will not make the algorithm any better, but rather much worse. Finally, the R2 coefficient of determination shows that thread levels hold a pretty significant impact on the Quicksort algorithm even if it's not perfect, it shows that the impact is more of a loss in speedup and runtime rather than the opposite when adding more threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc5b5a-cd4f-4e7a-a3bf-955586e61fcf",
   "metadata": {},
   "source": [
    "**In conclusion, despite using parallelism, the parallel quicksort implementation does not achieve a scalable performance for our workload. Confidence intervals computation reveal the high variability in execution times, while the linear regression on speedup confirms that increasing the number of threads does not improve performance in any way. This highlights that parallelism does not guarantee performance gains in our context.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
